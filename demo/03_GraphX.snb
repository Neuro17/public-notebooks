{"metadata":{"name":"GraphX","user_save_timestamp":"1970-01-01T01:00:00.000Z","auto_save_timestamp":"1970-01-01T01:00:00.000Z","language_info":{"name":"scala","file_extension":"scala","codemirror_mode":"text/x-scala"},"trusted":true,"customLocalRepo":null,"customRepos":null,"customDeps":null,"customImports":null,"customArgs":null,"customSparkConf":null},"cells":[{"metadata":{},"cell_type":"markdown","source":"# Analyse GitHub archives using GraphX"},{"metadata":{},"cell_type":"markdown","source":"_Trying to detect open source communies based on contributions_"},{"metadata":{},"cell_type":"markdown","source":"### **The size of the data**"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":":sh du -h /home/Sources/data-fellas/demo-base/datasets/github-events.json","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First some Spark manipulation "},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val sqlContext = new org.apache.spark.sql.SQLContext(sparkContext)\nimport sqlContext.implicits._","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val json = sqlContext.read.json(\"/home/Sources/data-fellas/demo-base/datasets/github-events.json\")","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The number of lines in the file"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"json.count","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The graph part "},{"metadata":{},"cell_type":"markdown","source":"We could use the *actors* and the *repos* as vertices, and use the *event* as relationship between them.\n\nThere are *id*s for actor and repo, so we can directly use them in GraphX as such."},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"import org.apache.spark.rdd._\nimport org.apache.spark.graphx._","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RDD vertices {Actors U Repos}"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"import org.apache.spark.sql.functions._\nval actors = json.select($\"actor.id\" as \"id\", \n                         $\"actor.login\" as \"name\", \n                         lit(0) as \"discr\")\nval repos = json.select($\"repo.id\" as \"id\", \n                        $\"repo.name\" as \"name\", \n                        lit(1) as \"discr\")\n()","outputs":[]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val vertices = (actors unionAll repos).map(x => (x.getAs[Long](0), (x.getAs[Int](1), x.getAs[String](2))))","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RDD of Edges "},{"metadata":{},"cell_type":"markdown","source":"Now an **RDD** with the edges (including reverse ones, that is from repo to actor)"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// None → repo to actor\n// Some(\"PushEvent\") → actor pushed on repo\nval edges:RDD[Edge[Option[String]]] = json.select($\"type\", $\"actor.id\" as \"actor\", $\"repo.id\" as \"repo\")\n                                          .flatMap{ x =>\n                                            val event = x.getAs[String](0)\n                                            val actor = x.getAs[Long](1)\n                                            val repo = x.getAs[Long](2)\n                                            List(\n                                              Edge(actor, repo, Some(event)), \n                                              Edge(repo, actor, None) // there is a link from repo to actor\n                                            )\n                                          }","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Graph"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val graph = Graph(vertices, edges)","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Open source working community "},{"metadata":{},"cell_type":"markdown","source":"A very very simple example of such extraction would simply be to extract the connected components "},{"metadata":{},"cell_type":"markdown","source":"So that, a component is the actors and repos having connections between them but not with other actor or repos. A connection being a collaboration."},{"metadata":{},"cell_type":"markdown","source":"### Computing connected components "},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val cc = graph.connectedComponents","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The `cc` variable is the original graph but vertives' payload/properties is only the cluster to which is belongs. The cluster is characterized by the smallest `VertexId` in the cluster."},{"metadata":{},"cell_type":"markdown","source":"#### Number of connected components "},{"metadata":{},"cell_type":"markdown","source":"Computing the number of clusters can easily be done by counting the number of distinct `payload` for the vertices."},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"<span><strong style=\"color: red\">{cc.vertices.map(_._2).distinct.count}</strong> connected components</span>","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Clusters by language "},{"metadata":{},"cell_type":"markdown","source":"We can try to concentrate our analysis to specific languages, since we don't have the language information in the events data (we need extra call to the GitHub API for that) we'll take a naive approach, that is, **we'll only consider the repo having the language in their name** -- albeit it's not 100% safe."},{"metadata":{},"cell_type":"markdown","source":"#### Utility functions"},{"metadata":{},"cell_type":"markdown","source":"The following function compute retrieves the cluster for a given cluster."},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val ccVerticesDF = cc.vertices.toDF(\"id\", \"cluster\")\ndef cluster(lgg:String) = {\n  val reposForLgg = repos.filter(lower($\"name\") contains lgg).select($\"id\").map(_.getAs[Long](0)).collect.toList\n  val b = sparkContext.broadcast(reposForLgg)\n  \n  val clusterIds = sparkContext.broadcast(ccVerticesDF.filter($\"id\" isin (b.value:_*))\n                                                      .select(\"cluster\")\n                                                      .map(_.getAs[Long](0)\n                                        ).collect.toList)\n  \n  val clusters = ccVerticesDF.filter($\"cluster\" isin (clusterIds.value:_*))\n                             .groupBy(\"cluster\")\n                             .agg(count($\"id\") as \"c\")\n  clusters.join(repos, $\"cluster\" === $\"id\").dropDuplicates(Array(\"id\")).orderBy($\"c\" desc)\n}","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Javascript"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val js = cluster(\"js\")","outputs":[]},{"metadata":{"trusted":true,"collapsed":false},"cell_type":"markdown","source":"## Scala"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val scala = cluster(\"scala\")","outputs":[]}],"nbformat":4}